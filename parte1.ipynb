{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-05-28T04:27:21.250758Z",
     "iopub.execute_input": "2022-05-28T04:27:21.251072Z",
     "iopub.status.idle": "2022-05-28T04:27:23.049639Z",
     "shell.execute_reply.started": "2022-05-28T04:27:21.251037Z",
     "shell.execute_reply": "2022-05-28T04:27:23.048631Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def read_data_from_csv(file_path: str) -> pd.DataFrame:\n    return pd.read_csv(file_path)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-28T04:27:23.096264Z",
     "iopub.execute_input": "2022-05-28T04:27:23.096575Z",
     "iopub.status.idle": "2022-05-28T04:27:23.101681Z",
     "shell.execute_reply.started": "2022-05-28T04:27:23.096542Z",
     "shell.execute_reply": "2022-05-28T04:27:23.100757Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "REVIEWS_DATASET_PATH = './datasets/Womens_Clothing_E-Commerce_Reviews.csv'\n",
    "reviews_dataset = read_data_from_csv(file_path=REVIEWS_DATASET_PATH)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.512054Z",
     "iopub.execute_input": "2022-05-27T19:53:01.512328Z",
     "iopub.status.idle": "2022-05-27T19:53:01.538596Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.512296Z",
     "shell.execute_reply": "2022-05-27T19:53:01.535312Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resumen del dataset\n",
    "\n",
    "El dataset contiene 23486 filas, cada una correspondiente a una reseña con unas 10 columnas correspondiente a variables explicadas a continuación.\n",
    "### Descripción de cada columna\n",
    "\n",
    "| Columna  | Descripción  |\n",
    "|---|---|\n",
    "| Clothing ID | Identificador numérico de la prenda especificada en la crítica |\n",
    "| Age | Valor numérico correspondiente a la edad de la persona que realizo la crítica |\n",
    "| Title | Titulo o encabezado de la crítica |\n",
    "| Reviw Text | Contenido de la reseña realizada |\n",
    "| Rating | Valor numérico en el rango del 1 al 5, siendo el 1 representante de máxima inconformidad y el 5 correspondiente al mejor valor posible |\n",
    "| Recommended IND | Valor entre 0 y 1, representando respectivamente si el cliente no recomienda el producto o por el contrario si lo recomienda |\n",
    "| Positive Feedback Count | Cantidad de reseñas positivas recibidas para el mismo producto |\n",
    "| Division Name | Nombre de la división a la cual pertenece el producto |\n",
    "| Department Name | Nombre del departamento al cual pertenece el producto |\n",
    "| Class Name | Nombre de la clase al cual pertenece el producto |\n",
    "\n",
    "### Categoria de variables\n",
    "\n",
    "- Variables Cuantitativas : Age, Positive Feedback Count.\n",
    "\n",
    "- Variables Cualitativas : Clothing ID, Title, Review Text, Rating, Recommended IND, Division Name, Department Name, Class Name.\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset.dtypes",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.540192Z",
     "iopub.status.idle": "2022-05-27T19:53:01.540691Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.540433Z",
     "shell.execute_reply": "2022-05-27T19:53:01.540461Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.545734Z",
     "iopub.execute_input": "2022-05-27T19:53:01.546148Z",
     "iopub.status.idle": "2022-05-27T19:53:01.560106Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.546105Z",
     "shell.execute_reply": "2022-05-27T19:53:01.559065Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Limpieza de Datos",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### DATOS NULOS",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Observamos la cantidad de nulos que poseen cada columna y el porcentaje que representan dicha cantidad de datos en cada columna",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset.isna().sum()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.883931Z",
     "iopub.execute_input": "2022-05-27T19:53:01.884364Z",
     "iopub.status.idle": "2022-05-27T19:53:01.89866Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.884321Z",
     "shell.execute_reply": "2022-05-27T19:53:01.897557Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset.isnull().sum() *100 / len(reviews_dataset.index)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.909625Z",
     "iopub.execute_input": "2022-05-27T19:53:01.910144Z",
     "iopub.status.idle": "2022-05-27T19:53:01.926428Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.91011Z",
     "shell.execute_reply": "2022-05-27T19:53:01.924359Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Debido a que el trabajo a realizar con el dataset consiste en clasificar una reseña como una crítica positiva o una negativa a partir del texto en el campo “Review Text”, decidimos eliminar las columnas que no resultan de utilidad para dicho objetivo. De esta forma, obtenemos un dataset con las columnas necesarias para identificar las distintas prendas, el texto escrito en la reseña y por último la columna \"Rating\" para el desarrollo del ítem D, motivo por el cual conservamos dicha columna.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "columns_eliminate= ['Unnamed: 0','Age','Title','Recommended IND','Positive Feedback Count','Division Name','Department Name','Class Name']\nreviews_dataset.drop(columns_eliminate,axis = 'columns',inplace = True)\n\nreviews_dataset",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.927403Z",
     "iopub.status.idle": "2022-05-27T19:53:01.92778Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.927597Z",
     "shell.execute_reply": "2022-05-27T19:53:01.927623Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Por ultimo dado a que las filas con valores inválidos en la columna de \"Review Text\" son un total de 845 que representan una cantidad menor al 4% de la totalidad de los datos, optamos por eliminar dichas filas.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset.dropna(inplace=True)\nreviews_dataset.shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.929615Z",
     "iopub.status.idle": "2022-05-27T19:53:01.930244Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.929989Z",
     "shell.execute_reply": "2022-05-27T19:53:01.930015Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Construccion de una nueva variable:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Verificación:\nCompruebo que la variable Rating no posea valores fuera de rango (1 al 5) antes de operar con dicha columna",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset.Rating.value_counts()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.931516Z",
     "iopub.status.idle": "2022-05-27T19:53:01.932142Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.93188Z",
     "shell.execute_reply": "2022-05-27T19:53:01.931907Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "reviews_dataset['Rating Category'] = reviews_dataset['Rating'].apply(lambda x: 'Negativo' if x <= 3 else 'Positivo')\nreviews_dataset",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-27T19:53:01.933356Z",
     "iopub.status.idle": "2022-05-27T19:53:01.934064Z",
     "shell.execute_reply.started": "2022-05-27T19:53:01.933776Z",
     "shell.execute_reply": "2022-05-27T19:53:01.933827Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "reviews = reviews_dataset.loc[:, ['Review Text', 'Rating Category']]\nreviews",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "le = LabelEncoder()\nreviews['Rating Category'] = le.fit_transform(reviews['Rating Category'])\nreviews",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "reviews.dtypes",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "stop_words = set(stopwords.words('english'))\nvect = CountVectorizer(stop_words=stop_words)\nvect_df = vect.fit_transform(reviews['Review Text'].values.tolist())\nvect_df.shape",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(vect_df, reviews['Rating Category'], test_size=0.3, random_state=10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Naive Bayes",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "nb_clf = MultinomialNB()\nnb_clf.fit(X_train, y_train)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "y_nb_pred = nb_clf.predict(X_test)\nprint(classification_report(y_test, y_nb_pred, digits=3))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Regresión Logística",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Para poder utilizar l función, Fit se deben verificar dos cosas:\n\ni. Que no haya datos NaN\n\nii. Que cada elemento en la fila X_train, sea un vector.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "lr = LogisticRegression(C=0.5, max_iter=150)\nlr.fit(X_train, y_train)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "y_lr_pred = lr.predict(X_test)\nprint(classification_report(y_test, y_lr_pred, digits=3))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Árboles de decisión",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Utilizamos Cross Validation para buscar los hiperparámetros del modelo que permitan obtener los mejores resultados. De esta forma, utilizaremos una de las métricas para buscar los valores que den mejores resultados y utilizarlos para crear nuestro modelo. Dada la cantidad de parámetros y el rango de los mismos utilizamos una randomSearch en lugar de una GridSearch, fijando la cantidad de iteraciones en 20.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "params = {'criterion':['gini','entropy'],\n               'min_samples_split': list(range(2,25)),\n               'min_samples_leaf':list(range(1,10)),\n               'ccp_alpha':np.linspace(0,0.05,2),\n               'max_depth':list(range(1,15))}\n\nbase_tree = tree.DecisionTreeClassifier() \n\n\ntree_random_cv = RandomizedSearchCV(estimator=base_tree,param_distributions = params, scoring= \"f1\", cv= 7, n_iter= 20, random_state = 10) \n\ntree_random_cv.fit(X_train,y_train)\n\nprint(tree_random_cv.best_params_)\nprint(tree_random_cv.best_score_)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tree_model = tree_random_cv.best_estimator_\n\ny_tree_pred = tree_model.predict(X_test)\n\nprint(classification_report(y_test, y_tree_pred, digits=3))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Random Forest",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Al igual que para un arbol de decicion buscamos los hiperparametros que nos den mejores resultados para el modelo de Random Forest. En el modelo de Random Forest vamos a utilizar cross validation para los hipervalores: 'criterion', 'min_samples_split', 'min_samples_leaf', 'ccp_alpha' y 'max_depth'.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "params = {'criterion':['gini','entropy'],'min_samples_split': list(range(2,25)),'min_samples_leaf':list(range(1,10)),\n          'ccp_alpha':np.linspace(0,0.05,2),'max_depth':list(range(1,15)),'n_estimators': [15,30,60] }\n\n\nforest_model= RandomForestClassifier() \n\nr_forest_random_cv = RandomizedSearchCV(estimator=forest_model,param_distributions = params, scoring= 'f1', cv= 7, \n                                      n_iter= 20, random_state = 10) \n\nr_forest_random_cv.fit(X_train,y_train)\n\nprint(r_forest_random_cv.best_params_)\nprint(r_forest_random_cv.best_score_)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Aclaración:\nSe utilizo RandomSearch para realizar el proceso de CrossValidation con el fin de utilizar un rango de valores para los hiperparametros, lo que por el contrario si se utiliza GridSearch se debe dar una cantidad de posibles valores para cada parametro mas reducida.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "best_forest_model = r_forest_random_cv.best_estimator_\n\ny_forest_pred = best_forest_model.predict(X_test)\n\nprint(classification_report(y_test, y_forest_pred, digits=3))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}